#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå™¨
ä»Excelæ–‡ä»¶è¯»å–'ç¤ºä¾‹query'åˆ—å¹¶è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡
"""

import os
import pandas as pd
import json
import time
from datetime import datetime
from src.task_executor import TaskExecutor
from src.config import config
from src.logger_config import get_logger

logger = get_logger(__name__)

class BatchExecutor:
    """æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå™¨ - ä¸“é—¨å¤„ç†ç¤ºä¾‹query"""
    
    def __init__(self, task_output_base_dir="output"):
        self.excel_file = "éªŒæ”¶é€šè¿‡æ•°æ®/æ ‡è´é‡‡é›†éœ€æ±‚.xlsx"
        self.target_sheets = ['çˆ±å¥‡è‰º', 'æ‡‚è½¦å¸', 'ç¾å›¢å¤–å–', 'é¥¿äº†ä¹ˆ']
        self.output_base_dir = "batch_output_0701"
        self.task_output_base_dir = task_output_base_dir  # å•ä¸ªä»»åŠ¡çš„è¾“å‡ºåŸºç¡€ç›®å½•
        self.failed_queries = []
        self.success_count = 0
        self.total_count = 0
        self.start_time = None
        
    def run_batch_tasks(self):
        """è¿è¡Œæ‰¹é‡ä»»åŠ¡"""
        logger.info("=" * 60)
        logger.info("ğŸš€ æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå™¨")
        logger.info("=" * 60)
        
        self.start_time = time.time()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_base_dir, exist_ok=True)
        
        # æ£€æŸ¥Excelæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.excel_file):
            logger.error(f"âŒ Excelæ–‡ä»¶ä¸å­˜åœ¨: {self.excel_file}")
            return False
        
        logger.info(f"ğŸ“Š æ­£åœ¨è¯»å–Excelæ–‡ä»¶: {self.excel_file}")
        
        # è¯»å–Excelæ–‡ä»¶
        try:
            excel_data = pd.ExcelFile(self.excel_file)
            logger.info(f"ğŸ“‹ å‘ç°sheets: {excel_data.sheet_names}")
            
            # æ£€æŸ¥ç›®æ ‡sheetsæ˜¯å¦å­˜åœ¨
            available_sheets = [sheet for sheet in self.target_sheets if sheet in excel_data.sheet_names]
            missing_sheets = [sheet for sheet in self.target_sheets if sheet not in excel_data.sheet_names]
            
            if missing_sheets:
                logger.warning(f"âš ï¸  ä»¥ä¸‹sheetsä¸å­˜åœ¨: {missing_sheets}")
            
            if not available_sheets:
                logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç›®æ ‡sheets")
                return False
            
            logger.info(f"âœ… å°†å¤„ç†ä»¥ä¸‹sheets: {available_sheets}")
            
            # é€ä¸ªå¤„ç†sheet
            for sheet_name in available_sheets:
                self._process_sheet(excel_data, sheet_name)
            
            # ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
            self._generate_report()
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
            return False
        
        return True
    
    def _process_sheet(self, excel_data, sheet_name):
        """å¤„ç†å•ä¸ªsheet"""
        logger.info(f"\nğŸ“‘ å¤„ç†sheet: {sheet_name}")
        
        try:
            # è¯»å–sheetæ•°æ®
            df = pd.read_excel(excel_data, sheet_name=sheet_name)
            logger.info(f"ğŸ“Š æ•°æ®è¡Œæ•°: {len(df)}")
            logger.info(f"ğŸ“‹ åˆ—å: {list(df.columns)}")
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['ç¤ºä¾‹query']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                logger.error(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
                return
            
            # ä¸ºè¿™ä¸ªsheetåˆ›å»ºè¾“å‡ºç›®å½•
            sheet_output_dir = os.path.join(self.output_base_dir, sheet_name)
            os.makedirs(sheet_output_dir, exist_ok=True)
            
            # æå–æ‰€æœ‰queriesï¼ˆåªå¤„ç†ç¤ºä¾‹queryï¼‰
            all_queries = self._extract_queries_from_sheet(df)
            logger.info(f"ğŸ“ ä»{sheet_name}æå–åˆ° {len(all_queries)} ä¸ªç¤ºä¾‹æŸ¥è¯¢")
            
            # æ‰§è¡Œqueries
            self._execute_queries(all_queries, sheet_name, sheet_output_dir)
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†sheet {sheet_name} å¤±è´¥: {e}")
    
    def _extract_queries_from_sheet(self, df):
        """ä»sheetä¸­æå–æ‰€æœ‰queriesï¼ˆåªå¤„ç†ç¤ºä¾‹queryï¼‰"""
        all_queries = []
        
        for index, row in df.iterrows():
            # åªå¤„ç†ç¤ºä¾‹query
            example_query = row.get('ç¤ºä¾‹query')
            if pd.notna(example_query) and str(example_query).strip():
                all_queries.append({
                    'query': str(example_query).strip(),
                    'type': 'ç¤ºä¾‹query',
                    'row': index + 1
                })
        
        return all_queries
    
    def _execute_queries(self, queries, sheet_name, output_dir):
        """æ‰§è¡Œä¸€ç»„queries"""
        logger.info(f"\nğŸ”„ å¼€å§‹æ‰§è¡Œ{sheet_name}çš„{len(queries)}ä¸ªæŸ¥è¯¢...")
        
        # åˆ›å»ºä»»åŠ¡æ‰§è¡Œå™¨ï¼Œä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºåŸºç¡€ç›®å½•
        executor = TaskExecutor(output_base_dir=self.task_output_base_dir)
        
        # è®°å½•æ‰§è¡Œç»“æœ
        execution_results = []
        
        for i, query_info in enumerate(queries, 1):
            query = query_info['query']
            query_type = query_info['type']
            row_num = query_info['row']
            
            logger.info(f"\n--- æ‰§è¡ŒæŸ¥è¯¢ {i}/{len(queries)} ---")
            logger.info(f"ğŸ“ æŸ¥è¯¢: {query}")
            logger.info(f"ğŸ“‹ ç±»å‹: {query_type}")
            logger.info(f"ğŸ“ æ¥æºè¡Œ: {row_num}")
            
            # æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹è·Ÿè¸ªå¯åŠ¨çš„åº”ç”¨
            task_launched_apps = set()
            
            try:
                # æ‰§è¡Œä»»åŠ¡
                start_time = time.time()
                success = executor.run_task(query)
                end_time = time.time()
                execution_time = end_time - start_time
                
                # # æå–å½“å‰ä»»åŠ¡å¯åŠ¨çš„åº”ç”¨
                # if hasattr(executor, 'task_data') and executor.task_data:
                #     self._extract_launched_apps(executor.task_data, task_launched_apps)
                
                # æŒ‰queryåˆ›å»ºç›®æ ‡ç›®å½•ï¼ˆé™åˆ¶æ–‡ä»¶åé•¿åº¦ï¼Œé¿å…è·¯å¾„è¿‡é•¿ï¼‰
                safe_query = query[:30].replace('/', '_').replace('\\', '_').replace(':', '_').replace('|', '_')
                target_output = os.path.join(output_dir, f"{safe_query}")
                
                # ç§»åŠ¨è¾“å‡ºæ–‡ä»¶åˆ°sheetç›®å½•
                # ä½¿ç”¨executorçš„å®é™…è¾“å‡ºç›®å½•è€Œä¸æ˜¯ç¡¬ç¼–ç çš„"output"
                original_output = executor.output_dir
                if os.path.exists(original_output):
                    # å¦‚æœç›®æ ‡ç›®å½•å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                    if os.path.exists(target_output):
                        import shutil
                        shutil.rmtree(target_output)
                    
                    # ç§»åŠ¨ç›®å½•
                    import shutil
                    shutil.move(original_output, target_output)
                    logger.info(f"ğŸ“ è¾“å‡ºå·²ä¿å­˜åˆ°: {target_output}")
                
                # è®°å½•ç»“æœ
                result = {
                    'query': query,
                    'type': query_type,
                    'row': row_num,
                    'success': success,
                    'execution_time': execution_time,
                    'output_dir': target_output,
                    'launched_apps': list(task_launched_apps),  # è®°å½•æ­¤ä»»åŠ¡å¯åŠ¨çš„åº”ç”¨
                    'timestamp': datetime.now().isoformat()
                }
                
                if success:
                    logger.info(f"âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼Œç”¨æ—¶ {execution_time:.1f} ç§’")
                    self.success_count += 1
                else:
                    logger.error(f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼Œç”¨æ—¶ {execution_time:.1f} ç§’")
                    self.failed_queries.append(query_info)
                
                execution_results.append(result)
                self.total_count += 1
                
                # # åœæ­¢å½“å‰ä»»åŠ¡å¯åŠ¨çš„åº”ç”¨ï¼Œä¸ºä¸‹ä¸€ä¸ªä»»åŠ¡å‡†å¤‡
                # logger.info(f"ğŸ›‘ åœæ­¢å½“å‰ä»»åŠ¡å¯åŠ¨çš„åº”ç”¨...")
                # if task_launched_apps:
                #     logger.info(f"ğŸ¯ å½“å‰ä»»åŠ¡å¯åŠ¨äº† {len(task_launched_apps)} ä¸ªåº”ç”¨: {list(task_launched_apps)}")
                #     executor.device.clean_apps(target_apps=list(task_launched_apps))
                #     logger.info(f"âœ… åº”ç”¨å·²åœæ­¢ï¼Œä¸ºä¸‹ä¸€ä¸ªä»»åŠ¡å‡†å¤‡")
                # else:
                #     logger.info("â„¹ï¸  å½“å‰ä»»åŠ¡æœªå¯åŠ¨æ–°åº”ç”¨ï¼Œæ‰§è¡Œå¸¸è§„åœæ­¢")
                #     executor.device.clean_apps()  # ä»ç„¶æ‰§è¡Œåœæ­¢ï¼Œç¡®ä¿çŠ¶æ€å¹²å‡€
                
                # # çŸ­æš‚ä¼‘æ¯ï¼Œé¿å…è®¾å¤‡è¿‡çƒ­
                # time.sleep(3)
                
            except KeyboardInterrupt:
                logger.warning(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
                # ä¿å­˜ä¸­æ–­å‰çš„ç»“æœ
                self._save_execution_results(execution_results, sheet_name, output_dir)
                raise
            except Exception as e:
                logger.error(f"âŒ æ‰§è¡ŒæŸ¥è¯¢æ—¶å‡ºé”™: {e}")
                self.failed_queries.append(query_info)
                self.total_count += 1
                
                # è®°å½•å¤±è´¥ç»“æœ
                result = {
                    'query': query,
                    'type': query_type,
                    'row': row_num,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
                execution_results.append(result)
        
        # ä¿å­˜æ‰§è¡Œç»“æœ
        self._save_execution_results(execution_results, sheet_name, output_dir)
    
    def _save_execution_results(self, results, sheet_name, output_dir):
        """ä¿å­˜æ‰§è¡Œç»“æœ"""
        results_file = os.path.join(output_dir, f"{sheet_name}_execution_results.json")
        
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“„ æ‰§è¡Œç»“æœå·²ä¿å­˜: {results_file}")
    
    def _extract_launched_apps(self, task_data: dict, launched_apps: set):
        """ä»ä»»åŠ¡æ•°æ®ä¸­æå–å¯åŠ¨çš„åº”ç”¨"""
        if not task_data or "data" not in task_data:
            return
        
        for step_data in task_data["data"]:
            if "plan" in step_data:
                plans = step_data["plan"]
                if isinstance(plans, list):
                    for plan in plans:
                        if isinstance(plan, dict):
                            # æ£€æŸ¥æ˜¯å¦æ˜¯Openæ“ä½œ
                            if plan.get("type", "").lower() == "open":
                                # æå–åº”ç”¨åŒ…å
                                if "package" in plan and plan["package"]:
                                    launched_apps.add(plan["package"])
                                    logger.info(f"ğŸ“± è®°å½•å¯åŠ¨åº”ç”¨: {plan['package']}")
                                # å¦‚æœæ²¡æœ‰åŒ…åï¼Œå°è¯•ä»é…ç½®ä¸­è·å–
                                elif "app" in plan and plan["app"]:
                                    app_name = plan["app"]
                                    from src.config import config
                                    if app_name in config.app_packages:
                                        package_name = config.app_packages[app_name]
                                        launched_apps.add(package_name)
                                        logger.info(f"ğŸ“± è®°å½•å¯åŠ¨åº”ç”¨: {package_name} (æ¥è‡ª{app_name})")
    
    def _generate_report(self):
        """ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š"""
        total_time = time.time() - self.start_time if self.start_time else 0
        
        logger.info(f"\n" + "=" * 60)
        logger.info("ğŸ“Š æ‰¹é‡æ‰§è¡ŒæŠ¥å‘Š")
        logger.info("=" * 60)
        logger.info(f"âœ… æˆåŠŸ: {self.success_count}")
        logger.info(f"âŒ å¤±è´¥: {len(self.failed_queries)}")
        logger.info(f"ğŸ“ˆ æ€»è®¡: {self.total_count}")
        logger.info(f"ğŸ“Š æˆåŠŸç‡: {(self.success_count/self.total_count*100):.1f}%" if self.total_count > 0 else "0%")
        logger.info(f"â° æ€»ç”¨æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        logger.info(f"âš¡ å¹³å‡æ¯ä¸ªæŸ¥è¯¢: {total_time/self.total_count:.1f} ç§’" if self.total_count > 0 else "0 ç§’")
        
        if self.failed_queries:
            logger.info(f"\nâŒ å¤±è´¥çš„æŸ¥è¯¢:")
            for i, query_info in enumerate(self.failed_queries, 1):
                logger.info(f"  {i}. {query_info['query']} (ç±»å‹: {query_info['type']})")
        
        # ä¿å­˜æŠ¥å‘Š
        report = {
            'summary': {
                'total': self.total_count,
                'success': self.success_count,
                'failed': len(self.failed_queries),
                'success_rate': (self.success_count/self.total_count*100) if self.total_count > 0 else 0
            },
            'failed_queries': self.failed_queries,
            'timestamp': datetime.now().isoformat()
        }
        
        report_file = os.path.join(self.output_base_dir, "batch_execution_report.json")
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main(task_output_base_dir="output"):
    """ä¸»å‡½æ•°"""
    try:
        logger.info("ğŸ¤– æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå™¨å¯åŠ¨")
        logger.info("ğŸ“‹ ç›®æ ‡sheets: çˆ±å¥‡è‰º, æ‡‚è½¦å¸, ç¾å›¢å¤–å–, é¥¿äº†ä¹ˆ")
        logger.info("ğŸ“ åªå¤„ç†'ç¤ºä¾‹query'åˆ—çš„æŸ¥è¯¢")
        logger.info("âš ï¸  æ³¨æ„: è¯·ç¡®ä¿è®¾å¤‡å·²è¿æ¥ä¸”å±å¹•ä¿æŒäº®èµ·")
        logger.info(f"ğŸ“ å•ä¸ªä»»åŠ¡è¾“å‡ºåŸºç¡€ç›®å½•: {os.path.abspath(task_output_base_dir)}")
        
        # è®©ç”¨æˆ·é€‰æ‹©æ‰§è¡Œæ¨¡å¼
        logger.info("\nğŸ“‹ æ‰§è¡Œé€‰é¡¹:")
        logger.info("1. å…¨éƒ¨æ‰§è¡Œ (çˆ±å¥‡è‰º + æ‡‚è½¦å¸ + ç¾å›¢å¤–å– + é¥¿äº†ä¹ˆ)")
        logger.info("2. é€‰æ‹©ç‰¹å®šsheets")
        logger.info("3. åªæ‰§è¡Œä¸€ä¸ªsheetè¿›è¡Œæµ‹è¯•")
        
        choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
        
        batch_executor = BatchExecutor(task_output_base_dir=task_output_base_dir)
        
        if choice == "2":
            # è®©ç”¨æˆ·é€‰æ‹©sheets
            available_sheets = ['çˆ±å¥‡è‰º', 'æ‡‚è½¦å¸', 'ç¾å›¢å¤–å–', 'é¥¿äº†ä¹ˆ']
            logger.info("\nå¯é€‰æ‹©çš„sheets:")
            for i, sheet in enumerate(available_sheets, 1):
                logger.info(f"{i}. {sheet}")
            
            selected = input("\nè¯·è¾“å…¥è¦æ‰§è¡Œçš„sheetåºå·(ç”¨é€—å·åˆ†éš”ï¼Œå¦‚: 1,3): ").strip()
            try:
                indices = [int(x.strip()) - 1 for x in selected.split(',')]
                batch_executor.target_sheets = [available_sheets[i] for i in indices if 0 <= i < len(available_sheets)]
                logger.info(f"âœ… å·²é€‰æ‹©: {batch_executor.target_sheets}")
            except:
                logger.error("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å…¨éƒ¨sheets")
        
        elif choice == "3":
            # æµ‹è¯•æ¨¡å¼ï¼Œåªæ‰§è¡Œç¬¬ä¸€ä¸ªsheet
            sheet_name = input("\nè¯·è¾“å…¥è¦æµ‹è¯•çš„sheetåç§° (çˆ±å¥‡è‰º/æ‡‚è½¦å¸/ç¾å›¢å¤–å–/é¥¿äº†ä¹ˆ): ").strip()
            if sheet_name in ['çˆ±å¥‡è‰º', 'æ‡‚è½¦å¸', 'ç¾å›¢å¤–å–', 'é¥¿äº†ä¹ˆ']:
                batch_executor.target_sheets = [sheet_name]
                logger.info(f"ğŸ§ª æµ‹è¯•æ¨¡å¼: å°†åªæ‰§è¡Œ {sheet_name} çš„ç¤ºä¾‹æŸ¥è¯¢")
            else:
                logger.error("âŒ æ— æ•ˆçš„sheetåç§°")
                return
        
        logger.info(f"\nğŸ“‹ æ‰§è¡Œè®¡åˆ’:")
        logger.info(f"   ç›®æ ‡sheets: {batch_executor.target_sheets}")
        logger.info(f"   å¤„ç†åˆ—: 'ç¤ºä¾‹query'")
        logger.info(f"   è¾“å‡ºç›®å½•: {batch_executor.output_base_dir}")
        
        confirm = input("\næ˜¯å¦å¼€å§‹æ‰§è¡Œï¼Ÿ(y/N): ").strip().lower()
        if confirm in ['n', 'no', 'å¦']:
            logger.info("âŒ ä»»åŠ¡å·²å–æ¶ˆ")
            return
        
        success = batch_executor.run_batch_tasks()
        
        if success:
            logger.info("\nğŸ‰ æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼")
        else:
            logger.error("\nâŒ æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå¤±è´¥")
            
    except KeyboardInterrupt:
        logger.warning(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰¹é‡æ‰§è¡Œ")
    except Exception as e:
        logger.error(f"\nâŒ æ‰¹é‡æ‰§è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šå•ä¸ªä»»åŠ¡çš„è¾“å‡ºåŸºç¡€ç›®å½•
    import sys
    task_output_dir = "output"
    if len(sys.argv) > 1:
        task_output_dir = sys.argv[1]
        logger.info(f"ğŸ“ ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„ä»»åŠ¡è¾“å‡ºç›®å½•: {task_output_dir}")
    
    main(task_output_base_dir=task_output_dir) 